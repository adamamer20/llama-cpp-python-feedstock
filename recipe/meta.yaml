{% set name = "llama_cpp_python" %}
{% set version = "0.2.65" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/llama_cpp_python-{{ version }}.tar.gz
  sha256: 5d8b8bec70576176f213b7abedda267aedafda1d165b4a30b3ebf9d3df597d55
  patches:
    # Asks cdll to look for the library in the path as well.
    - try-lib-in-path.patch

build:
  number: 0
  script:
    {% macro cmake_args(key, value) -%}
    - export CMAKE_ARGS="${CMAKE_ARGS} {{ key }}={{ value }}"    # [unix]
    - set CMAKE_ARGS=%CMAKE_ARGS% {{ key }}={{ value }}          # [win]
    {%- endmacro %}

    {{ cmake_args("-DLLAMA_BUILD", "OFF") }}
    {{ cmake_args("-DLLAVA_BUILD", "OFF") }}

    - {{ PYTHON }} -m pip install . -vv

requirements:
  build:
    - python                                 # [build_platform != target_platform]
    - cross-python_{{ target_platform }}     # [build_platform != target_platform]

    - {{ compiler('c') }}
    - {{ compiler('cxx') }}
    - cmake
    - make
    - pkgconfig
  host:
    - python >=3.8
    - scikit-build-core >=0.9.2
    - pip
  run:
    - python >=3.8
    - typing-extensions >=4.5.0
    - numpy >=1.20.0
    - diskcache >=5.6.1
    - jinja2 >=2.11.3
    - llama.cpp

    # Split into llama-cpp-python-server
    - uvicorn >=0.22.0
    - fastapi >=0.100.0
    - pydantic-settings >=2.0.1
    - sse-starlette >=1.6.1
    - starlette-context >=0.3.6,<0.4


test:
  imports:
    - llama_cpp
  commands:
    - pip check
  requires:
    - pip

about:
  home: https://github.com/abetlen/llama-cpp-python
  summary: Python bindings for the llama.cpp library
  license: Apache-2.0 AND MIT
  license_file:
    - LICENSE.md
    - vendor/llama.cpp/LICENSE
    - vendor/llama.cpp/gguf-py/LICENSE
    - vendor/llama.cpp/kompute/LICENSE

extra:
  recipe-maintainers:
    - YYYasin19
    - sodre
